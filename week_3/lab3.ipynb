{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69z7xsgG0dUE"
   },
   "source": [
    "# Week 3 lab: Convolutional networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PuYkI8fT0YYH"
   },
   "source": [
    "This week we will get some hands-on experience with convolutional networks on 2D images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PA84zBjcua7y"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "# from google.colab import files\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# import seaborn as sns\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize']  = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"tensorflow\"\n",
    "\n",
    "# def save_fig(fig_id, tight_layout=True):\n",
    "#     path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "#     print(\"Saving figure\", fig_id)\n",
    "#     if tight_layout:\n",
    "#         plt.tight_layout()\n",
    "#     plt.savefig(path, format='png', dpi=300)\n",
    "#     files.download(PROJECT_ROOT_DIR+'/images/'+CHAPTER_ID+'/'+fig_id + \".png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YpzHjuUvxgrr"
   },
   "source": [
    "Now you need to define the network properties. Fill in the missing structure to implement a multi-layer linear, dense network for `model_dense` and a multi-layer convolutional network for `model`. For the convnet, remember that the output of every `Conv2d` and `MaxPool2d` layer is a 3D tensor of shape *(height, width, channels)*. The *width* and *height* dimensions tend to shrink as we go deeper in the network. The number of channels is controlled by the first argument passed to the Conv2D layers (e.g. 32 or 64). Remember to check the impact of padding parameters and maxpooling output dimensions when structuring the dimensions of the conv2d layers.\n",
    "\n",
    "The next step would be to feed our last output tensor (of shape (X, Y, N)) into a densely-connected classifier network like those you are already familiar with: a stack of Dense layers. These classifiers process vectors, which are 1D, whereas our current output is a 3D tensor. So first, we will have to flatten our 3D outputs to 1D, and then add a few Dense layers after that. We are going to do 10-way classification, so use a final layer with 10 outputs and a `nn.Softmax` activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "sQE1avXc0R1Z",
    "outputId": "541c1394-7746-40bf-ad25-ff5d87aa1b5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (faltten1): Flatten()\n",
      "  (fc1): Linear(in_features=144, out_features=64, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (softmax1): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "# input size torch.Size([32, 1, 28, 28]) torch.Size([32])\n",
    "model_dense = nn.Sequential(collections.OrderedDict(\n",
    "    [(\"flatten1\", nn.Flatten()),\n",
    "     (\"dense11\", nn.Linear(28*28, 28*28)),\n",
    "     (\"dense12\", nn.Linear(28*28, 28*28)),\n",
    "     (\"dense13\", nn.Linear(28*28, 28*28)),\n",
    "     (\"dense14\", nn.Linear(28*28, 28*28)),\n",
    "     (\"dense15\", nn.Linear(28*28, 28*28)),\n",
    "     (\"dense2\", nn.Linear(28*28, 28)),\n",
    "     (\"dense3\", nn.Linear(28, 10)),\n",
    "     (\"softmax1\", nn.Softmax(dim=1))]))\n",
    "\n",
    "model = nn.Sequential(collections.OrderedDict(\n",
    "    [(\"conv1\", nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))),\n",
    "     (\"relu1\", nn.ReLU()),\n",
    "     (\"maxpool1\", nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
    "     (\"conv2\", nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))),\n",
    "     (\"relu2\", nn.ReLU()),\n",
    "     (\"maxpool2\", nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
    "     (\"conv3\", nn.Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1))),\n",
    "     (\"relu3\", nn.ReLU()),\n",
    "     (\"faltten1\", nn.Flatten()),\n",
    "     (\"fc1\", nn.Linear(in_features=144, out_features=64, bias=True)),\n",
    "     (\"relu4\", nn.ReLU()),\n",
    "     (\"fc2\", nn.Linear(in_features=64, out_features=10, bias=True)),\n",
    "     (\"softmax1\", nn.Softmax(dim=1))]))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eDL77wM2CfU"
   },
   "source": [
    "Now here's what our network looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "hs6msmo32zV3",
    "outputId": "21cc8064-1456-4a4e-90bc-3fa4c265d50c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (faltten1): Flatten()\n",
      "  (fc1): Linear(in_features=144, out_features=64, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (softmax1): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3SOqIE02Tur"
   },
   "source": [
    "\n",
    "As you can see, our (3, 3, 64) outputs were flattened into vectors of shape (576,), before going through two Dense layers.\n",
    "\n",
    "Now, let's train our convnet on the Fashion MNIST digits. You can[ learn more about the Fashion-MNIST data set](https://github.com/zalandoresearch/fashion-mnist).\n",
    "\n",
    "We specify the root directory to store the dataset, download the training data, if not present on the local machine, and then apply the transforms. ToTensor to turn images into Tensor so we can directly use it with our network. The dataset is stored in the dataset class named `train_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "ficLeQynybw1",
    "outputId": "3c904897-e74b-47e1-f237-205ffd2c8ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data/FashionMNIST\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           ) Dataset FashionMNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/FashionMNIST\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Use standard FashionMNIST dataset\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()                                 \n",
    "    ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()                                 \n",
    "    ])\n",
    ")\n",
    "print(train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transform from cpu to gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model_dense = model_dense.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGCMMnNBwk3t"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "epoch_print_gap = 1\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:   \n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        if epoch == 1 or epoch % epoch_print_gap == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch, float(loss_train)))\n",
    "\n",
    "def test_loop(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmHOauL40nNv"
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "\n",
    "loader = torch.utils.data.DataLoader(train_set, batch_size = 32)\n",
    "test_loader = torch.utils.data.DataLoader(test_set)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer_dense = optim.SGD(model_dense.parameters(), lr=lr)\n",
    "\n",
    "images, labels = next(iter(loader))\n",
    "grid = torchvision.utils.make_grid(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IHM4onO8wr3v",
    "outputId": "d1994c65-79c4-4013-e4b3-50ece90896dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-06 16:29:25.307682 Epoch 1, Training loss 4316.5978307724\n",
      "2020-02-06 16:29:35.582713 Epoch 2, Training loss 4314.678748130798\n",
      "2020-02-06 16:29:45.745500 Epoch 3, Training loss 4304.730551481247\n",
      "2020-02-06 16:29:55.897483 Epoch 4, Training loss 3814.7490000724792\n",
      "2020-02-06 16:30:05.924064 Epoch 5, Training loss 3381.405956864357\n",
      "2020-02-06 16:30:12.288746 Epoch 6, Training loss 3325.06827712059\n",
      "2020-02-06 16:30:18.884717 Epoch 7, Training loss 3296.3310363292694\n",
      "2020-02-06 16:30:25.496828 Epoch 8, Training loss 3273.037854552269\n",
      "2020-02-06 16:30:32.587042 Epoch 9, Training loss 3253.6558911800385\n",
      "2020-02-06 16:30:39.492245 Epoch 10, Training loss 3238.309044480324\n",
      "2020-02-06 16:30:45.972120 Epoch 1, Training loss 4313.525923967361\n",
      "2020-02-06 16:30:52.236643 Epoch 2, Training loss 4283.107258558273\n",
      "2020-02-06 16:30:58.337148 Epoch 3, Training loss 3851.1111991405487\n",
      "2020-02-06 16:31:04.413401 Epoch 4, Training loss 3496.125617623329\n",
      "2020-02-06 16:31:10.578374 Epoch 5, Training loss 3276.061002969742\n",
      "2020-02-06 16:31:16.971242 Epoch 6, Training loss 3209.4221221208572\n",
      "2020-02-06 16:31:22.988732 Epoch 7, Training loss 3183.960088610649\n",
      "2020-02-06 16:31:29.077329 Epoch 8, Training loss 3168.5937002897263\n",
      "2020-02-06 16:31:35.226772 Epoch 9, Training loss 3157.2854179143906\n",
      "2020-02-06 16:31:41.482327 Epoch 10, Training loss 3149.8400217294693\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 10, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = loader,\n",
    ")\n",
    "\n",
    "training_loop(                                                      \n",
    "    n_epochs = 10, \n",
    "    optimizer = optimizer_dense,\n",
    "    model = model_dense,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yutyeB-fMkS2"
   },
   "source": [
    "Now run the test data through to see how the models got on. Compare the perfomance of Linear dense models and conv2D models. Experiment with different numbers and sizes of layers and kernel sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xa7UGRq5E8To"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -0.7193, Accuracy: 7227/10000 (72%)\n",
      "\n",
      "\n",
      "Test set: Average loss: -0.7728, Accuracy: 7766/10000 (78%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(model=model, test_loader = test_loader)\n",
    "test_loop(model=model_dense, test_loader = test_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "“Lab3Btorch-student.ipynb”的副本",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
